{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b46418-f3d6-4215-a590-51afa164e68e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1763714503.py, line 268)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 268\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"\\nStarting Comprehensive Experiment... (This will take a long time)\\n\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AILS Experiment Runner\n",
    "======================\n",
    "\n",
    "This is the main executable script for running the AILS experiments.\n",
    "It imports all core logic from 'ails_core.py' and runs the\n",
    "experiments within an 'if __name__ == \"__main__\"' block.\n",
    "\n",
    "This structure is required to make multiprocessing compatible with\n",
    "Jupyter notebooks, Windows, and macOS.\n",
    "\n",
    "To run:\n",
    "1.  Save this file as 'run_experiments.py'.\n",
    "2.  Save the other file as 'ails_core.py' in the same directory.\n",
    "3.  Run this file from your terminal:\n",
    "    python run_experiments.py\n",
    "    \n",
    "    ...or copy the contents of this file into a single\n",
    "    Jupyter Notebook cell and run it.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from ails_core import *\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXPERIMENT FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def run_comprehensive_experiment():\n",
    "    \"\"\"Execute the complete experimental framework\"\"\"\n",
    "    \n",
    "    print(\"\"\"\n",
    "    ╔════════════════════════════════════════════════════════════════╗\n",
    "    ║     ADAPTIVE INCREMENTAL LINE SEARCH (AILS) FRAMEWORK         ║\n",
    "    ║         Q1 Journal-Grade Comprehensive Evaluation              ║\n",
    "    ╚════════════════════════════════════════════════════════════════╝\n",
    "    \"\"\")\n",
    "    \n",
    "    # Initialize Q1-level configuration\n",
    "    config = ExperimentConfig(\n",
    "        grid_sizes=[50, 100, 200, 300, 400], # Extensive grid sizes\n",
    "        obstacle_densities=list(np.linspace(0.05, 0.40, 8)), # 8 density levels\n",
    "        trials_per_config=20,  # More trials for statistical power\n",
    "        start_goal_strategy='random', # CRITICAL: use random pairs\n",
    "        num_random_pairs=10,          # 10 random pairs per grid\n",
    "        use_multiprocessing=True,\n",
    "        num_workers=max(1, mp.cpu_count() - 2) # Leave 2 CPUs free\n",
    "    )\n",
    "    \n",
    "    # Run experiments\n",
    "    runner = ExperimentRunner(config)\n",
    "    df = runner.run_experiments()\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"EXPERIMENT FAILED: No results generated.\")\n",
    "        print(\"=\"*80)\n",
    "        return None, None\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPERIMENT COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total experiment data points (rows): {len(df)}\")\n",
    "    print(f\"Unique configurations: {len(df.groupby(['grid_size', 'obstacle_density', 'pattern', 'trial_id']))}\")\n",
    "    \n",
    "    # Statistical analysis\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STATISTICAL ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    stats_results = StatisticalAnalysis.analyze_results(df)\n",
    "    \n",
    "    # Print key findings\n",
    "    for alg in ['A*', 'Dijkstra', 'BFS']:\n",
    "        if alg in stats_results:\n",
    "            print(f\"\\n--- Analysis for {alg} ---\")\n",
    "            mean_imp, lower_imp, upper_imp = stats_results[alg]['time_improvement']['ails_vs_std']\n",
    "            print(f\"  AILS vs Standard Time: {mean_imp:.2f}% improvement (95% CI: [{lower_imp:.2f}, {upper_imp:.2f}])\")\n",
    "            print(f\"    - P-value (t-test): {stats_results[alg]['t_tests']['ails_vs_std']['p_value']:.2e}\")\n",
    "            print(f\"    - Effect size (Cohen's d): {stats_results[alg]['effect_sizes']['ails_vs_std']:.3f}\")\n",
    "            \n",
    "            mean_qual, lower_qual, upper_qual = stats_results[alg]['path_quality_ratio']\n",
    "            print(f\"  AILS Path Quality Ratio: {mean_qual:.3f} (95% CI: [{lower_qual:.3f}, {upper_qual:.3f}])\")\n",
    "            print(f\"    (1.0 = same as standard, >1.0 = worse path)\")\n",
    "    \n",
    "    if stats_results['tukey'].get('algorithm') is not None:\n",
    "        print(\"\\n--- Tukey's HSD (Algorithm) ---\")\n",
    "        print(stats_results['tukey']['algorithm'])\n",
    "\n",
    "    # Visualization\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATING VISUALIZATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Run all standard and new Q1-level plots\n",
    "    ComprehensiveVisualization.plot_performance_comparison(df)\n",
    "    ComprehensiveVisualization.plot_heatmaps(df)\n",
    "    ComprehensiveVisualization.plot_performance_distributions(df)\n",
    "    ComprehensiveVisualization.plot_scalability_analysis(df)\n",
    "    ComprehensiveVisualization.plot_tradeoff_analysis(df)\n",
    "    ComprehensiveVisualization.plot_faceted_heatmaps_by_pattern(df)\n",
    "    \n",
    "    # Generate LaTeX tables\n",
    "    if config.generate_latex_tables:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"GENERATING LATEX TABLES\")\n",
    "        print(\"=\"*80)\n",
    "        LatexTableGenerator.save_tables(df, stats_results)\n",
    "    \n",
    "    # Summary report\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    overall_improvement = df['ails_pred_time_improvement'].mean()\n",
    "    best_case = df['ails_pred_time_improvement'].max()\n",
    "    worst_case = df['ails_pred_time_improvement'].min()\n",
    "    \n",
    "    print(f\"Overall AILS Performance:\")\n",
    "    print(f\"  Average improvement: {overall_improvement:.2f}%\")\n",
    "    print(f\"  Best case improvement: {best_case:.2f}%\")\n",
    "    print(f\"  Worst case improvement: {worst_case:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nBest performing algorithm: {df.groupby('algorithm')['ails_pred_time_improvement'].mean().idxmax()}\")\n",
    "    print(f\"Best performing pattern: {df.groupby('pattern')['ails_pred_time_improvement'].mean().idxmax()}\")\n",
    "    \n",
    "    print(\"\\nFiles saved:\")\n",
    "    print(f\"  - CSV: results/data/experiment_results_*.csv\")\n",
    "    print(f\"  - Figures: results/figures/*.png\")\n",
    "    print(f\"  - LaTeX: results/analysis/latex_tables_*.tex\")\n",
    "    \n",
    "    return df, stats_results\n",
    "\n",
    "# ============================================================================\n",
    "# PARAMETER SENSITIVITY ANALYSIS (PSA)\n",
    "# ============================================================================\n",
    "\n",
    "def run_parameter_sensitivity_experiment():\n",
    "    \"\"\"Execute the PSA framework\"\"\"\n",
    "    \n",
    "    print(\"\"\"\n",
    "    ╔════════════════════════════════════════════════════════════════╗\n",
    "    ║         PARAMETER SENSITIVITY ANALYSIS (PSA)                  ║\n",
    "    ╚════════════════════════════════════════════════════════════════╝\n",
    "    \"\"\")\n",
    "    \n",
    "    # PSA Configuration\n",
    "    psa_config = ExperimentConfig(\n",
    "        use_multiprocessing=True,\n",
    "        num_workers=max(1, mp.cpu_count() - 2)\n",
    "    )\n",
    "    psa_runner = ExperimentRunner(psa_config)\n",
    "    \n",
    "    # Define parameter ranges to test\n",
    "    window_sizes = [3, 5, 7, 9, 11]\n",
    "    lookaheads = [0, 3, 5, 7, 10]\n",
    "    \n",
    "    # Run the PSA\n",
    "    df_psa = psa_runner.run_sensitivity_analysis(window_sizes, lookaheads)\n",
    "    \n",
    "    if df_psa.empty:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PSA FAILED: No results generated.\")\n",
    "        print(\"=\"*80)\n",
    "        return None\n",
    "    \n",
    "    # Plot PSA results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATING PSA VISUALIZATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    ComprehensiveVisualization.plot_parameter_sensitivity(df_psa)\n",
    "    \n",
    "    print(\"\\nFiles saved:\")\n",
    "    print(f\"  - CSV: results/data/psa_results_*.csv\")\n",
    "    print(f\"  - Figures: results/figures/psa_results_*.png\")\n",
    "    \n",
    "    return df_psa\n",
    "\n",
    "# ============================================================================\n",
    "# QUICK DEMO\n",
    "# ============================================================================\n",
    "\n",
    "def quick_demo():\n",
    "    \"\"\"Run a quick demonstration with visualization\"\"\"\n",
    "    print(\"Running Quick Demo...\")\n",
    "    \n",
    "    # Generate sample grid\n",
    "    grid = AdvancedGridGenerator.generate(\n",
    "        100, 0.2, AdvancedGridGenerator.ObstaclePattern.CLUSTERED, seed=42\n",
    "    )\n",
    "    \n",
    "    start = (0, 0)\n",
    "    goal = (99, 99)\n",
    "    \n",
    "    # Initialize algorithms\n",
    "    config = ExperimentConfig()\n",
    "    ails = AdaptiveILS(grid, config)\n",
    "    \n",
    "    # Run A* with different configurations\n",
    "    result_std = ComprehensivePathfinding.a_star(grid, start, goal, None)\n",
    "    result_ails = ails.search(ComprehensivePathfinding.a_star, start, goal, 'predictive')\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"Standard A*: Time={result_std['time']:.4f}s, Visited={result_std['visited']}, Cost={result_std['cost']:.2f}\")\n",
    "    print(f\"AILS A*:     Time={result_ails['time']:.4f}s, Visited={result_ails['visited']}, Cost={result_ails['cost']:.2f}\")\n",
    "    if result_std['time'] > 0:\n",
    "        print(f\"Time Improvement: {((result_std['time'] - result_ails['time'])/result_std['time']*100):.1f}%\")\n",
    "    if result_std['cost'] > 0:\n",
    "        print(f\"Path Cost Ratio:  {(result_ails['cost']/result_std['cost']):.3f}\")\n",
    "\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)\n",
    "    \n",
    "    # Plot grid with paths\n",
    "    axes[0].imshow(grid, cmap='binary')\n",
    "    if result_std['path']:\n",
    "        path_array = np.array(result_std['path'])\n",
    "        axes[0].plot(path_array[:, 1], path_array[:, 0], 'r-', linewidth=2, label='Standard A*')\n",
    "    axes[0].set_title(f\"Standard A* Path\\nCost: {result_std['cost']:.2f}\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(grid, cmap='binary')\n",
    "    \n",
    "    # Show corridor\n",
    "    corridor = ails.corridor_builder.compute_adaptive_corridor(start, goal, 'predictive')\n",
    "    corridor_mask = np.ones_like(grid, dtype=float) * np.nan # Use NaN for empty\n",
    "    for point in corridor:\n",
    "        if 0 <= point[0] < 100 and 0 <= point[1] < 100:\n",
    "            corridor_mask[point[0], point[1]] = 1\n",
    "    axes[1].imshow(corridor_mask, cmap='Greens', alpha=0.3)\n",
    "    \n",
    "    if result_ails['path']:\n",
    "        path_array = np.array(result_ails['path'])\n",
    "        axes[1].plot(path_array[:, 1], path_array[:, 0], 'g-', linewidth=2, label='AILS')\n",
    "        \n",
    "    axes[1].set_title(f\"AILS Path with Adaptive Corridor\\nCost: {result_ails['cost']:.2f}\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# NOTEBOOK INTERFACE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # This __name__ == \"__main__\" block is ESSENTIAL for\n",
    "    # multiprocessing to work correctly, especially in\n",
    "    # Jupyter notebooks or when running as a script.\n",
    "    \n",
    "    print(\"Select an option in the 'if __name__ == \\\"__main__\\\":' block:\")\n",
    "    print(\"1. Run quick_demo()\")\n",
    "    print(\"2. Uncomment and run run_comprehensive_experiment()\")\n",
    "    print(\"3. Uncomment and run run_parameter_sensitivity_experiment()\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Your requested lines are below:\n",
    "    # ------------------------------------------------------------------------\n",
    "    \n",
    "    # 1. To run a short experiment (quick demo):\n",
    "    quick_demo()\n",
    "    \n",
    "    # 2. To run the whole experiment (uncomment the line below):\n",
    "     print(\"\\nStarting Comprehensive Experiment... (This will take a long time)\\n\")\n",
    "     df, stats = run_comprehensive_experiment()\n",
    "     print(\"\\nComprehensive Experiment Finished.\")\n",
    "    \n",
    "    # 3. To run the parameter sensitivity analysis (uncomment the line below):\n",
    "    # print(\"\\nStarting Parameter Sensitivity Analysis...\\n\")\n",
    "    # df_psa = run_parameter_sensitivity_experiment()\n",
    "    # print(\"\\nPSA Finished.\")\n",
    "    \n",
    "    print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851423d-d85c-4bf9-a2eb-6dce02ed06b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
