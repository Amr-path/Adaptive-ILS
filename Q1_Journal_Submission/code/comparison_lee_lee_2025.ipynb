{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with Lee & Lee 2025\n",
    "\n",
    "This notebook performs a direct comparison between AILS and the MCPP-GAK algorithm\n",
    "from Lee & Lee (2025) using the same Moving AI Lab benchmarks.\n",
    "\n",
    "**Reference:** Lee, C., & Lee, J. (2025). Multi-Agent Coverage Path Planning Using \n",
    "Graph-Adapted K-Means in Road Network Digital Twin. *Electronics*, 14(1), 89.\n",
    "\n",
    "**Author:** Amr Elshahed  \n",
    "**Institution:** Universiti Sains Malaysia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from AILS_complete import (\n",
    "    AILSPathfinder, MovingAIMapLoader, run_benchmark\n",
    ")\n",
    "\n",
    "# Set style\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "print(\"Lee & Lee 2025 Comparison Notebook\")\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lee & Lee 2025 Reported Results\n",
    "\n",
    "Results from Table 2 and Table 3 of the original paper.\n",
    "These are for MCPP (Multi-agent Coverage Path Planning) with different agent counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee & Lee 2025 results (from paper Tables 2-3)\n",
    "lee_lee_results = pd.DataFrame([\n",
    "    # den312d\n",
    "    {'map': 'den312d', 'k': 2, 'setting': 'arbitrary', 'max_length': 2249, 'time': 1226.56, 'iterations': 4},\n",
    "    {'map': 'den312d', 'k': 2, 'setting': 'clutter', 'max_length': 4889, 'time': 599.77, 'iterations': 2},\n",
    "    {'map': 'den312d', 'k': 5, 'setting': 'arbitrary', 'max_length': 1565, 'time': 504.49, 'iterations': 2},\n",
    "    {'map': 'den312d', 'k': 5, 'setting': 'clutter', 'max_length': 3491, 'time': 572.03, 'iterations': 2},\n",
    "    {'map': 'den312d', 'k': 10, 'setting': 'arbitrary', 'max_length': 623, 'time': 10746.30, 'iterations': 3},\n",
    "    {'map': 'den312d', 'k': 10, 'setting': 'clutter', 'max_length': 3057, 'time': 1660.64, 'iterations': 2},\n",
    "    {'map': 'den312d', 'k': 20, 'setting': 'arbitrary', 'max_length': 371, 'time': 19138.61, 'iterations': 2},\n",
    "    {'map': 'den312d', 'k': 20, 'setting': 'clutter', 'max_length': 3357, 'time': 672.46, 'iterations': 2},\n",
    "    \n",
    "    # ht_chantry\n",
    "    {'map': 'ht_chantry', 'k': 2, 'setting': 'arbitrary', 'max_length': 14921, 'time': 5979.80, 'iterations': 2},\n",
    "    {'map': 'ht_chantry', 'k': 2, 'setting': 'clutter', 'max_length': 14921, 'time': 5957.24, 'iterations': 2},\n",
    "    {'map': 'ht_chantry', 'k': 5, 'setting': 'arbitrary', 'max_length': 5081, 'time': 13221.50, 'iterations': 2},\n",
    "    {'map': 'ht_chantry', 'k': 5, 'setting': 'clutter', 'max_length': 10065, 'time': 4808.83, 'iterations': 2},\n",
    "    {'map': 'ht_chantry', 'k': 10, 'setting': 'arbitrary', 'max_length': 3601, 'time': 33464.44, 'iterations': 2},\n",
    "    {'map': 'ht_chantry', 'k': 10, 'setting': 'clutter', 'max_length': 7379, 'time': 4608.55, 'iterations': 2},\n",
    "    {'map': 'ht_chantry', 'k': 20, 'setting': 'arbitrary', 'max_length': 1847, 'time': 147405.96, 'iterations': 4},\n",
    "    {'map': 'ht_chantry', 'k': 20, 'setting': 'clutter', 'max_length': 7567, 'time': 4620.24, 'iterations': 2},\n",
    "    \n",
    "    # random-64-64-20\n",
    "    {'map': 'random-64-64-20', 'k': 2, 'setting': 'arbitrary', 'max_length': 6539, 'time': 1152.05, 'iterations': 2},\n",
    "    {'map': 'random-64-64-20', 'k': 2, 'setting': 'clutter', 'max_length': 6539, 'time': 1082.83, 'iterations': 2},\n",
    "    {'map': 'random-64-64-20', 'k': 5, 'setting': 'arbitrary', 'max_length': 1295, 'time': 6531.38, 'iterations': 3},\n",
    "    {'map': 'random-64-64-20', 'k': 5, 'setting': 'clutter', 'max_length': 4099, 'time': 958.85, 'iterations': 2},\n",
    "    {'map': 'random-64-64-20', 'k': 10, 'setting': 'arbitrary', 'max_length': 1309, 'time': 962.04, 'iterations': 2},\n",
    "    {'map': 'random-64-64-20', 'k': 10, 'setting': 'clutter', 'max_length': 2833, 'time': 947.77, 'iterations': 2},\n",
    "    {'map': 'random-64-64-20', 'k': 20, 'setting': 'arbitrary', 'max_length': 817, 'time': 34094.00, 'iterations': 3},\n",
    "    {'map': 'random-64-64-20', 'k': 20, 'setting': 'clutter', 'max_length': 3785, 'time': 1025.53, 'iterations': 2},\n",
    "])\n",
    "\n",
    "print(\"Lee & Lee 2025 MCPP-GAK Results:\")\n",
    "print(lee_lee_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run AILS on Same Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark maps used in Lee & Lee 2025\n",
    "BENCHMARK_MAPS = {\n",
    "    'den312d': '../data/benchmark_maps/den312d.map',\n",
    "    'ht_chantry': '../data/benchmark_maps/ht_chantry.map',\n",
    "    'random-64-64-20': '../data/benchmark_maps/random-64-64-20.map'\n",
    "}\n",
    "\n",
    "NUM_SCENARIOS = 100  # Scenarios per map\n",
    "\n",
    "ails_results = []\n",
    "\n",
    "for map_name, map_path in BENCHMARK_MAPS.items():\n",
    "    print(f\"\\nProcessing {map_name}...\")\n",
    "    \n",
    "    if not os.path.exists(map_path):\n",
    "        print(f\"  Map not found: {map_path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Load map\n",
    "        grid = MovingAIMapLoader.load_map(map_path)\n",
    "        print(f\"  Grid size: {grid.shape}\")\n",
    "        print(f\"  Traversable: {np.sum(grid == 0)} cells\")\n",
    "        \n",
    "        # Run AILS experiments\n",
    "        results = run_benchmark(grid, NUM_SCENARIOS, seed=42)\n",
    "        \n",
    "        # Aggregate results\n",
    "        for method, result_list in results.items():\n",
    "            times = [r.time_ms for r in result_list if r.path_found]\n",
    "            nodes = [r.nodes_visited for r in result_list if r.path_found]\n",
    "            \n",
    "            if times:\n",
    "                ails_results.append({\n",
    "                    'map': map_name,\n",
    "                    'method': method,\n",
    "                    'time_mean_ms': np.mean(times),\n",
    "                    'time_std_ms': np.std(times),\n",
    "                    'nodes_mean': np.mean(nodes),\n",
    "                    'nodes_std': np.std(nodes),\n",
    "                    'success_rate': len(times) / len(result_list) * 100,\n",
    "                    'num_scenarios': len(result_list)\n",
    "                })\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "\n",
    "df_ails = pd.DataFrame(ails_results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AILS Results on Lee & Lee 2025 Benchmarks:\")\n",
    "print(df_ails.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare methodological differences\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHODOLOGICAL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "| Aspect            | Lee & Lee 2025 (MCPP-GAK)    | AILS (This Work)           |\n",
    "|-------------------|------------------------------|----------------------------|\n",
    "| Problem Type      | Multi-agent coverage (MCPP)  | Single-agent pathfinding   |\n",
    "| Algorithm Base    | Graph-Adapted K-Means        | Corridor-constrained A*    |\n",
    "| Search Strategy   | Clustering + ILS             | Bresenham + Adaptive A*    |\n",
    "| Optimality        | Heuristic (near-optimal)     | Optimal within corridor    |\n",
    "| Agent Support     | Multi-agent (k=2-40)         | Single-agent               |\n",
    "| Adaptivity        | Iterative balancing          | Local density-based        |\n",
    "| Benchmarks        | Moving AI Lab                | Moving AI Lab (shared)     |\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-map comparison visualization\n",
    "if len(df_ails) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "    \n",
    "    for idx, map_name in enumerate(BENCHMARK_MAPS.keys()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get AILS results for this map\n",
    "        df_map = df_ails[df_ails['map'] == map_name]\n",
    "        \n",
    "        if len(df_map) > 0:\n",
    "            methods = df_map['method'].values\n",
    "            times = df_map['time_mean_ms'].values\n",
    "            stds = df_map['time_std_ms'].values\n",
    "            \n",
    "            x = range(len(methods))\n",
    "            ax.bar(x, times, yerr=stds, capsize=5, alpha=0.7)\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels([m.replace('_', '\\n') for m in methods], fontsize=8)\n",
    "            ax.set_ylabel('Time (ms)')\n",
    "            ax.set_title(map_name)\n",
    "            ax.set_yscale('log')\n",
    "    \n",
    "    plt.suptitle('AILS Performance on Lee & Lee 2025 Benchmarks', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/results/ails_lee_lee_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Node Reduction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate node reduction compared to standard A*\n",
    "if len(df_ails) > 0:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"NODE REDUCTION ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for map_name in BENCHMARK_MAPS.keys():\n",
    "        df_map = df_ails[df_ails['map'] == map_name]\n",
    "        \n",
    "        if len(df_map) == 0:\n",
    "            continue\n",
    "            \n",
    "        std_nodes = df_map[df_map['method'] == 'standard_astar']['nodes_mean'].values\n",
    "        \n",
    "        if len(std_nodes) > 0:\n",
    "            std_nodes = std_nodes[0]\n",
    "            \n",
    "            print(f\"\\n{map_name}:\")\n",
    "            print(f\"  Standard A* nodes: {std_nodes:.1f}\")\n",
    "            \n",
    "            for method in ['ails_base', 'ails_adaptive']:\n",
    "                ails_nodes = df_map[df_map['method'] == method]['nodes_mean'].values\n",
    "                if len(ails_nodes) > 0:\n",
    "                    ails_nodes = ails_nodes[0]\n",
    "                    reduction = (1 - ails_nodes / std_nodes) * 100\n",
    "                    print(f\"  {method}: {ails_nodes:.1f} nodes ({reduction:.1f}% reduction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Table for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX table for paper\n",
    "if len(df_ails) > 0:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LATEX TABLE FOR PAPER\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    latex = \"\"\"\\\\begin{table}[ht]\n",
    "\\\\centering\n",
    "\\\\caption{AILS Performance on Lee \\\\& Lee 2025 Benchmark Maps}\n",
    "\\\\label{tab:lee_comparison}\n",
    "\\\\begin{tabular}{lcccc}\n",
    "\\\\toprule\n",
    "Map & Method & Time (ms) & Nodes & Success (\\\\%) \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "    \n",
    "    for _, row in df_ails.iterrows():\n",
    "        method_short = row['method'].replace('standard_', 'std_').replace('ails_', 'ails-')\n",
    "        latex += f\"{row['map']} & {method_short} & {row['time_mean_ms']:.2f} & {row['nodes_mean']:.0f} & {row['success_rate']:.1f} \\\\\\\\ \\n\"\n",
    "    \n",
    "    latex += \"\"\"\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\\\\end{table}\"\"\"\n",
    "    \n",
    "    print(latex)\n",
    "    \n",
    "    # Save LaTeX table\n",
    "    with open('../data/results/lee_comparison_table.tex', 'w') as f:\n",
    "        f.write(latex)\n",
    "    print(\"\\nTable saved to ../data/results/lee_comparison_table.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Comparison analysis complete!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
